# Facial Recognition System for Access Control
This repository presents the implementation of a facial recognition system developed for access control purposes. The system utilizes a Siamese network architecture to compare face embeddings extracted through MediaPipe FaceMesh, facilitating user registration and identification. The system also integrates a circular motion capture technique to enhance recognition accuracy by collecting multiple embeddings for comparison.

# Description

The system leverages state-of-the-art deep learning techniques, including a **Siamese network** model, to perform facial recognition. Using **MediaPipe FaceMesh**, facial landmarks are detected to generate **embeddings**, which are then stored for future comparisons. A **circular capture** process is incorporated to increase recognition reliability by collecting **multiple embeddings** of a user's face, even under varying conditions. This project aims to provide a reliable and efficient method for access control in secure environments.

## System Overview

- **Face Detection**: The system employs MediaPipe FaceMesh to extract facial landmarks, which are then used to generate face embeddings.
- **Siamese Network**: A deep learning model trained to compare facial embeddings and determine similarity for identity verification.
- **Circular Capture Mechanism**: A technique to improve recognition by capturing multiple embeddings through a circular motion, reducing the likelihood of misidentifications.
- **User Registration and Recognition**: The system supports both user registration and face-based recognition. User information is stored locally, and face embeddings are used for comparison during future recognition attempts.
- **Web Interface**: The system includes interactive widgets to facilitate user interactions in a Jupyter notebook environment.
## Technical Description

### Model Architecture

The core of the system is a Siamese network designed to learn the similarity between pairs of face embeddings. The network is trained to minimize the distance between embeddings of the same individual and maximize the distance between embeddings of different individuals. This network is deployed to compare the embedding of a detected face with stored embeddings and determine if a match exists.

- **Input**: A pair of face embeddings, generated by MediaPipe FaceMesh.
- **Output**: A similarity score representing the degree of match between the two embeddings.
### Face Embedding Extraction

Face embeddings are extracted using MediaPipe FaceMesh, a lightweight and efficient tool for detecting 468 facial landmarks. The embeddings are stored as vector representations of the face geometry, which are then compared for identity verification.

### Circular Capture Process

To enhance the accuracy of the facial recognition system, the circular capture process involves capturing multiple face embeddings as the user moves their head in a circular motion. This technique mitigates issues such as partial occlusions or poor lighting by averaging the embeddings collected during the circular motion.

### Local Storage and Recognition

- **Embeddings Storage**: Face embeddings, along with user data (first name, last name, gender), are stored in a local file system. The embeddings are saved in a `.npy` file, and the user data is stored in a `.json` file.
- **Recognition**: When a face is detected, the system compares the generated embedding with stored embeddings using the Siamese network. If a match is found, the user is authenticated. Otherwise, the system initiates the circular capture process to collect additional embeddings for more accurate recognition.
## Installation

### Prerequisites

To run this system, ensure that Python 3.6 or higher is installed. The system has been tested with the following libraries:

- `torch`: For the deep learning model.
- `opencv-python`: For image processing and video capture.
- `mediapipe`: For face mesh detection and landmark extraction.
- `faiss`: For efficient similarity search.
- `PIL`: For image handling and manipulation.
- `ipywidgets` and `IPython`: For the interactive UI components in Jupyter.

### Dependencies

To install the required libraries, run the following command:
    ```bash
     pip install -r requirements.txt

## File Descriptions:
```app/```: Contains the core application logic, including:

```siamese.py```: Defines the Siamese network model.

```embeddings.py```: Handles face embedding extraction.

```user_storage.py```: Manages the local storage of user data and embeddings.

```capture.py```: Manages the capture process for face embeddings.

```ui_widgets.py```: Defines the interactive widgets for user input and feedback.

```js_snippets.py```: Includes JavaScript code for video streaming and facial landmark visualization.

```main.py```: The main entry point of the application, responsible for initializing the system and running the recognition process.

```requirements.txt```: Lists all required Python libraries and dependencies.

```README.md```: This document, describing the system and its usage.

# Methodology
## Siamese Network for Face Recognition
The Siamese network is trained using pairs of face embeddings. Each pair is labeled as either a match (same person) or a non-match (different person). The network learns to minimize the distance between embeddings of the same individual and maximize the distance between embeddings of different individuals. This results in a robust model capable of identifying individuals based on facial features.

## MediaPipe FaceMesh
MediaPipe FaceMesh provides an efficient method for detecting 468 facial landmarks in real-time. These landmarks are then used to generate embeddings that represent the geometry of the face. These embeddings are the foundation for the recognition system.

## Circular Capture
The circular capture process improves recognition accuracy by collecting multiple embeddings as the user moves their head in a circular motion. This approach reduces issues like partial face occlusion or variations in lighting, which can degrade the performance of traditional facial recognition systems.

# Usage
1. Setup: Install the necessary dependencies by running the command:
    ```bash
    pip install -r requirements.txt

2. Run the Application: Start the Jupyter notebook or run the script main.py in your Python environment.

3. Register a New User: The system will prompt the user to provide their name and gender. The face embeddings will then be captured and stored.

4. Recognition: The system will detect faces and compare the generated embeddings with stored embeddings to recognize the user.

5. Circular Capture for Recognition: If the initial recognition fails, the system will initiate a circular capture process to improve accuracy by collecting additional embeddings.

# Contributions
Contributions are welcome! Please feel free to fork the repository and submit pull requests for improvements, bug fixes, or new features. Contributions can include, but are not limited to:

- Enhancements to the model architecture or training process.

- Improvements to the user interface.

- Code optimizations or bug fixes.

# License
This project is licensed under the [MIT License](LICENSE). See the [LICENSE](LICENSE) file for more details.
# Acknowledgments
- MediaPipe: For providing the FaceMesh model for facial landmark detection.

- PyTorch: For deep learning framework support.

- Faiss(Facebook Ai Similarity Search): For efficient similarity search in large datasets.

